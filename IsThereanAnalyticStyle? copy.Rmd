---
title: "Is There an Analytic Style?"
description: |
  Stylometric analysis of analytic and continental philosophy.
author:
  - name: Jesse Powell
date: "'r Sys.Date()'"
output: radix::radix_article
---
```{r}
#PreProcessing

library(stylo)

raw.corpus <- load.corpus(files = "all", 
                          corpus.dir = "philosophy_style_corpus",
                          encoding = "UTF-8")

tokenized.corpus <- txt.to.words.ext(raw.corpus, 
                                     language = "English.all",
                                     preserve.case = (FALSE))

```

```{r}
summary(tokenized.corpus)

```

```{r}


pca.corpus <- txt.to.features(tokenized.corpus, features = "w", ngram.size = 1)

pca.corpus
```

```{r}

```

```{r}
#Feature Extraction

corpus.char.3.grams <- txt.to.features(corpus.no.pronouns, 
                                       ngram.size = 3,
                                       features = "c")
```

```{r}
sliced.corpus <- make.samples(corpus.char.3.grams, 
                              sample.size = 277,
                              sampling = "no.sampling")

frequent.features <- make.frequency.list(sliced.corpus, 
                                         head = 20)

freqs <- make.table.of.frequencies(tokenized.corpus, 
                                   features = frequent.features)

culled.freqs <- perform.culling(freqs, 
                                culling.level = 85)

```

```{r}
#Statistical Analysis

stylo(corpus.dir = "philosophy_style_corpus",
      mfw.min = 277,
      mfw.max = 277,
      analysis.type = "PCR", 
      sampling = "no.sampling", 
      sample.size = 10000, 
      custom.graph.title = "Analytic vs Humanities Style",
      pca.visual.flavour = "classic",
      colors.on.graphs = "colors",
      write.png.file = TRUE, gui = FALSE)


```



```{r}

```

```{r}
stylo(corpus.dir = "philosophy_style_corpus", 
      mfw.min = 277, 
      mfw.max = 277,
      analysis.type = "CA", 
      sampling = "no.sampling", 
      sample.size = 10000, 
      custom.graph.title = "Style",
      write.png.file = TRUE, gui = FALSE)

```


```{r}

stylo(corpus.dir = "philosophy_style_corpus", 
      mfw.min = 1, 
      mfw.max = 277,
      analysis.type = "BCT", 
      sampling = "no.sampling", 
      sample.size = 10000, 
      custom.graph.title = "Style",
      write.png.file = TRUE, gui = FALSE)

```

```{r}
stylo.network(corpus.dir = "philosophy_style_corpus",
              mfw.min = 277, 
              mfw.max = 84305,
              write.png.file = TRUE, 
              gui = FALSE)

```

```{r}


```

```{r}
library(tidyr)
library(tidytext)
library(tidyverse)
library(readtext)
library(quanteda)
library(quanteda.corpora)
library(ggplot2)
library(dplyr)
library(topicmodels)
library(caret)
library(waffle)
library(tm)
library(methods)
library(quanteda.corpora)
library(lubridate)
library(lda)
library(scales)
library(ape)
library(viridis)
library(heatmaply)
```

```{r}

#This clustering Analysis is meant to contrast with the previous one generated by stylometry. This clustering should be by features extracted by tokenizing the texts.
mystopwords <- read_lines("my.stopwords.txt")
style_data <- readtext("/Users/jesserussellpowell/philosophy_style_corpus/",
                       docvarsfrom = "filenames", 
                       docvarnames = c("author", "title", "year"), 
                       dvsep = "_")


style_corp <- corpus(style_data)

style_toks <- tokens(style_corp, 
                     remove_punct = TRUE, 
                     remove_numbers = TRUE)
style_toks <- tokens_tolower(style_toks)
style_toks <- tokens_remove(style_toks, 
                            mystopwords,f 
                            padding = TRUE)
style_dfm <- dfm(style_toks, 
                 remove_punct = TRUE, 
                 remove_numbers = TRUE, 
                 remove = mystopwords)

style_dfm <- dfm_remove(style_dfm, c(stopwords("english"), mystopwords,"chapter", "der", "die", "ist", "das","und", "nicht", "eine", "a", "satz", "von", "den", "wir", "dass", "f", "q", "x", "sind","es","kann","durch", "der", "die", "ist", "das","und", "nicht", "eine", "satz", "von", "den", "one", "h", "can", "h", "c", "us", "p", "ein", "mean", "y", "b", "e", "n", "marx", "two", "tar35", "cn", "ist", "dass", "die", "der", "nicht", "sie", "1960", "2007", "word_and_object.html", "08", "www.marxists.org", "www.abika.com", "sentec", "theori", "probabl", "proposit", "ontolog", "capit", "languag", "sentenc", "frequenc", "falsifi", "industri", "phenomenolog", "sequenc", "labour-pow", "commod", "relat", "possibl"))

a <- featnames(style_dfm)
lapply(mystopwords, function(x){
  a[str_detect(a, x)]
})

weighted_corp <- dfm_weight(style_dfm, 
                             scheme = c("prop"))


weighted_corp <- dfm_remove(weighted_corp, c(stopwords("english"), mystopwords,"chapter", "der", "die", "ist", "das","und", "nicht", "eine", "a", "satz", "von", "den", "wir", "dass", "f", "q", "x", "sind","es","kann","durch", "der", "die", "ist", "das","und", "nicht", "eine", "satz", "von", "den", "one", "h", "can", "h", "c", "us", "p", "ein", "mean", "y", "b", "e", "n", "marx", "two", "tar35", "cn", "ist", "dass", "die", "der", "nicht", "sie", "1960", "2007", "word_and_object.html", "08", "www.marxists.org", "www.abika.com", "sentec", "theori", "probabl", "proposit", "ontolog", "capit", "languag", "sentenc", "frequenc", "falsifi", "industri", "phenomenolog", "sequenc", "labour-pow", "commod", "relat", "possibl"))

a <- featnames(weighted_corp)
lapply(mystopwords, function(x){
  a[str_detect(a, x)]
})

style_simil <- textstat_simil(weighted_corp, 
                        selection = NULL, 
                        margin = c("documents", "features"),
                        method = c("correlation"))

style_clust <- hclust(style_simil, 
                      method = "complete")
mypal = c("#440154FF","#481567FF","#482677FF","#453781FF","#404788FF","#39568CFF","#33638DFF","#2D708EFF","#287D8EFF","#238A8DFF","#1F968BFF","#20A387FF","#29AF7FFF","#3CBB75FF","#55C667FF","#73D055FF","#95D840FF","#B8DE29FF","#DCE319FF","#FDE725FF")

clus20 = cutree(style_clust,20)

plot(as.phylo(style_clust), 
     type = "phylogram", 
     tip.color = mypal[clus20], 
     cex = 1.2)
```

```{r}

cols <- c("#440154FF","#FDE725FF")

style_dfm <- dfm_remove(style_dfm, c(stopwords("english"), mystopwords,"chapter", "der", "die", "ist", "das","und", "nicht", "eine", "a", "satz", "von", "den", "wir", "dass", "f", "q", "x", "sind","es","kann","durch", "der", "die", "ist", "das","und", "nicht", "eine", "satz", "von", "den", "one", "h", "can", "h", "c", "us", "p", "ein", "mean", "y", "b", "e", "n", "marx", "two", "tar35", "cn", "ist", "dass", "die", "der", "nicht", "sie", "1960", "2007", "word_and_object.html", "08", "www.marxists.org", "www.abika.com", "sentec", "theori", "probabl", "proposit", "ontolog", "capit", "languag", "sentenc", "frequenc", "falsifi", "industri", "phenomenolog", "sequenc", "labour-pow", "commod", "relat", "possibl"))

key <- textstat_keyness(style_dfm, (docvars(style_dfm, 'author')) == "Analytic")

attr(key, 'documents') <- c('Analytic', '!Analytic')

textplot_keyness(key) +
  scale_colour_manual(values = cols, aesthetics = "colour", labels = c("Analytic", "Humanities"))

```

```{r}

raw.corpus <- load.corpus(files = "all", 
                          corpus.dir = "philosophy_style_corpus",
                          encoding = "UTF-8")

corpus.all <- txt.to.words.ext(raw.corpus, 
                                     language = "English.all",
                                     preserve.case = (FALSE))

corpus.analytic <- corpus.all[grep("Analytic", 
                                   names(corpus.all))]

corpus.humanities <- corpus.all[grep("Humanities",
                                     names(corpus.all))]

zeta.results <- oppose(primary.corpus = corpus.analytic,
                       secondary.corpus = corpus.humanities)

zeta.results$words.preferred[1:20]

zeta.results$words.avoided[1:20]

combined.features <- c(zeta.results$words.preferred[1:20],
                       zeta.results$words.avoided[1:20])

```

```{r}

classify(gui = TRUE,
         training.frequencies = NULL,
         test.frequencies = NULL,
         features = NULL,
         path = NULL,
         training.corpus.dir = "corpus.analytic",
         test.corpus.dir = "corpus.humanities")
```

```{r}
library(dplyr)
library(tidytext)

style_td <- tidy(style_corp)

title_words <- style_td %>%
  unnest_tokens(word,text) %>%
  count(author, word, sort = TRUE)

total_words <- title_words %>%
                group_by(author) %>%
                summarize(total = sum(n))

title_words <- left_join(title_words, total_words)

title_words_tf_idf <- title_words %>%
                bind_tf_idf(word, author, n) %>%
                arrange(desc(tf_idf))

title_words_tf_idf

library(ggplot2)

title_words_tf_idf %>%
  group_by(author) %>%
  top_n(10, tf_idf) %>%
  ungroup() %>%
  mutate(word = reorder(word, tf_idf)) %>%
  ggplot(aes(word, tf_idf, fill = author)) +
  geom_col(show.legen = TRUE) +
  labs(x = NULL, y = "tf_idf") +
  facet_wrap(~author,
             ncol = 2,
             scales = "free_y") +
    coord_flip()


```

```{r}
mystopwords <- read_lines("my.stopwords.txt")

style_data <- readtext("/Users/jesserussellpowell/philosophy_style_corpus/",
                       docvarsfrom = "filenames", 
                       docvarnames = c("author", "title", "year"), 
                       dvsep = "_")
style_corp <- corpus(style_data)
style_corp

style_dfm <- dfm(style_corp,
                 remove = c(stopwords("english"), mystopwords),
                 # ngrmas= L1,
                 stem = T,
                 remove_numbers = TRUE,
                 remove_punct = TRUE,
                 remove_symbols = TRUE,
                 verbose = T)

dfm1 <- dfm_remove(style_dfm, c(stopwords("english"), mystopwords,"chapter", "der", "die", "ist", "das","und", "nicht", "eine", "a", "satz", "von", "den", "wir", "dass", "f", "q", "x", "sind","es","kann","durch", "der", "die", "ist", "das","und", "nicht", "eine", "satz", "von", "den", "one", "h", "can", "h", "c", "us", "p", "ein", "mean", "y", "b", "e", "n", "marx", "two", "tar35", "cn", "ist", "dass", "die", "der", "nicht", "sie", "1960", "2007", "word_and_object.html", "08", "www.marxists.org", "www.abika.com", "sentec", "theori", "probabl", "proposit", "ontolog", "capit", "languag", "sentenc", "frequenc", "falsifi", "industri", "phenomenolog", "sequenc", "labour-pow", "commod", "relat", "possibl"))

a <- featnames(dfm1)
lapply(mystopwords, function(x){
  a[str_detect(a, x)]
})

freq_weight <- textstat_frequency(dfm1, n = 10, groups = "author")

ggplot(data = freq_weight, aes(x = nrow(freq_weight):1, y = frequency)) + geom_point() +
  facet_wrap(~ group, scales = "free") +
  coord_flip() + 
  scale_x_continuous(breaks = nrow(freq_weight):1,
                     labels = freq_weight$feature) +
  labs(x = NULL, y = "Relative frequency")
```
```{r}  
style_par_slim <- dfm_trim(dfm1, min_termfreq = 1000)

style_fcm <- fcm(style_par_slim)

feat <- names(topfeatures(style_fcm, 1))

size <- log(colSums(dfm_select(dfm1, feat)))

textplot_network(style_fcm, min_freq = .99, 
                 edge_color = "#FDE725FF")
```

```{r}
rolling.classify(write.png.file = TRUE,
                 classification.method = "svm",
                 mfw = 100,
                 training.set.sampling =
                   "normal.sampling",
                 slice.size = 5000,
                 slice.overlap = 4500)

```